{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e96faf-207a-4ea3-b9c6-c9a479e2dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acafc5f6-4399-4ce4-976a-8af3cc538d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"Dataset/reviews_train.csv\")\n",
    "df_test=pd.read_csv(\"Dataset/reviews_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b06754c-867c-4721-9947-584d236bbeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Panic In The Streets Richard Widmark plays ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you ask me the first one was really better ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a big fan a Faerie Tale Theatre and I've ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just finished reading a book about Dillinger...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greg Davis and Bryan Daly take some crazed sta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  In Panic In The Streets Richard Widmark plays ...      1\n",
       "1  If you ask me the first one was really better ...      0\n",
       "2  I am a big fan a Faerie Tale Theatre and I've ...      1\n",
       "3  I just finished reading a book about Dillinger...      0\n",
       "4  Greg Davis and Bryan Daly take some crazed sta...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0cfbb3-fbdb-466c-8c0f-694cf1ffe4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d97f3102-fc63-48d5-b123-23eebd35ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000)  # You can set num_words based on your vocabulary size\n",
    "tokenizer.fit_on_texts(df_train['review'])\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0bc4dfe-0b2b-43b2-b1f2-4ad75980706c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0     1     2     3     4     5     6    7     8     9\n",
      "0        46   539   159  5074  4381    81     8    1   389   552\n",
      "1         8    16    83    28    91    28   191  191   191   161\n",
      "2         5    29  2078     2    23    29   951    2    52   438\n",
      "3       506     9    73    57    45    10  1866  329     1   271\n",
      "4         1   169   746    16     1   169   646    4  2766  4716\n",
      "...     ...   ...   ...   ...   ...   ...   ...  ...   ...   ...\n",
      "24995   371    35     1   223   179    97   355   91   317  8217\n",
      "24996  1712   107   214     8     3  3725   349   17    84   154\n",
      "24997   179     9  1784     4    16     3   224    4  1119  1226\n",
      "24998  1680    69    20    11    39   103    30  126   203  2956\n",
      "24999    12  2479  1219    77  1273    20     5   64    37  4913\n",
      "\n",
      "[25000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Padding the sequences to a maximum length of 10 (you can choose the length based on your data)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=10, padding='post')\n",
    "\n",
    "# Convert to DataFrame to view the padded sequences\n",
    "padded_df_train = pd.DataFrame(padded_sequences)\n",
    "print(padded_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2c30b9-2d2d-4dbd-a9b8-45804f80d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(df_test['review'])\n",
    "padded_sequences_test = pad_sequences(sequences_test, maxlen=10, padding='post')\n",
    "padded_df_test = pd.DataFrame(padded_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc765a34-d133-46e8-a118-c6240cde2928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(10000, 128),\n",
    "    LSTM(128),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a54575a-8c4e-45cc-8fb0-15a162acb230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.6321 - loss: 0.6159 - val_accuracy: 0.7182 - val_loss: 0.5421\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7933 - loss: 0.4377 - val_accuracy: 0.7160 - val_loss: 0.5506\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8423 - loss: 0.3503 - val_accuracy: 0.7044 - val_loss: 0.6126\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.8799 - loss: 0.2700 - val_accuracy: 0.7074 - val_loss: 0.7406\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9088 - loss: 0.2072 - val_accuracy: 0.6956 - val_loss: 0.8681\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9318 - loss: 0.1632 - val_accuracy: 0.6994 - val_loss: 1.1284\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9460 - loss: 0.1297 - val_accuracy: 0.6954 - val_loss: 1.2123\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - accuracy: 0.9580 - loss: 0.1014 - val_accuracy: 0.6884 - val_loss: 1.2854\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 74ms/step - accuracy: 0.9675 - loss: 0.0829 - val_accuracy: 0.6882 - val_loss: 1.5664\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 78ms/step - accuracy: 0.9738 - loss: 0.0648 - val_accuracy: 0.6908 - val_loss: 1.6743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17d1cc15bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_df_train, df_train['label'], epochs=10, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8791d281-644f-4f5d-8d41-f9f6cce0b05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0776\n",
      "Test Accuracy: 0.9273599982261658\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(padded_df_test, df_test['label'])\n",
    "print(f\"Test Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2b23a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In Panic In The Streets Richard Widmark plays U.S. Navy doctor who has his week rudely interrupted with a corpse that contains plague. As cop Paul Douglas properly points out the guy died from two bullets in the chest. That's not the issue here, the two of them become unwilling partners in an effort to find the killers and anyone else exposed to the disease.<br /><br />As was pointed out by any number of people, for some reason director Elia Kazan did not bother to cast the small parts with anyone that sounds like they're from Louisiana. Having been to New Orleans where the story takes place I can personally attest to that. Richard Widmark and his wife Barbara Bel Geddes can be excused because as a Navy doctor he could be assigned there, but for those that are natives it doesn't work.<br /><br />But with plague out there and the news being kept a secret, the New Orleans PD starts a dragnet of the city's underworld. The dead guy came off a ship from Europe and he had underworld connections. A New Orleans wise guy played by Jack Palance jumps to a whole bunch of erroneous conclusions and starts harassing a cousin of the dead guy who is starting to show plague symptoms. Palance got rave reviews in the first film where he received notice.<br /><br />Personally my favorite in this film is Zero Mostel. This happened right before Mostel was blacklisted and around that time he made a specialty of playing would be tough guys who are really toadies. He plays the same kind of role in the Humphrey Bogart film, The Enforcer. Sadly I can kind of identify with Mostel in that last chase scene where he and Palance are being chased down by Widmark, Douglas, and half the New Orleans Police. Seeing the weight challenged Zero trying to keep up with Palance was something else because I'm kind of in Zero's league now in the heft department.<br /><br />Kazan kept the action going at a good clip, there's very little down time in this film. If there was any less it would be an Indiana Jones film. Panic In The Streets won an Oscar for Best Original Screenplay that year.<br /><br />Kazan also made good use of the New Orleans waterfront and the French Quarter. Some of the same kinds of shots are later used in On the Waterfront. In fact Panic In The Streets is about people not squealing when they really should in their own best interest. Very similar again to On the Waterfront.<br /><br />Panic In The Streets does everyone proud who was associated with it. Now why couldn't Elia Kazan get some decent New Orleans sounding people in the small roles.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b65e316-116d-4494-bf55-8a7c6d85b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "sample_review = \"The movie was best \"\n",
    "rew = tokenizer.texts_to_sequences([sample_review])  # Note the use of a list around the string\n",
    "\n",
    "# Pad the sequence to the same length used during training\n",
    "rew_padded = pad_sequences(rew, maxlen=256)  # Use the same maxlen as during training\n",
    "\n",
    "# Convert the padded sequence to a NumPy array (if not already)\n",
    "rew_padded = np.array(padded_df_train[0])\n",
    "prediction = model.predict(rew_padded.reshape(1, -1))\n",
    "sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "print(f\"Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61f4e5cd-65dd-4500-84de-b008bc78ae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 38s]\n",
      "val_accuracy: 0.701800008614858\n",
      "\n",
      "Best val_accuracy So Far: 0.7178000013033549\n",
      "Total elapsed time: 00h 20m 36s\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, \n",
    "                        output_dim=hp.Int('embedding_dim', min_value=32, max_value=256, step=32), \n",
    "                        input_length=256))\n",
    "    model.add(LSTM(units=hp.Int('lstm_units', min_value=32, max_value=256, step=32)))\n",
    "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='sentiment_analysis'\n",
    ")\n",
    "\n",
    "tuner.search(padded_df_train, df_train['label'], epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73ba9ee3-527c-47a7-ae0c-26a6e0147299",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ef38741-0c39-4c05-87ee-997f73ad89cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8114 - loss: 0.4268\n",
      "Test Accuracy: 0.7933200001716614\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = best_model.evaluate(padded_df_test, df_test['label'])\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2a4e397-963e-47dd-99f8-ea82a3366bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "sample_review = df_test['review'][10]\n",
    "rew = tokenizer.texts_to_sequences([sample_review])  # Note the use of a list around the string\n",
    "\n",
    "# Pad the sequence to the same length used during training\n",
    "rew_padded = pad_sequences(rew, maxlen=256)  # Use the same maxlen as during training\n",
    "\n",
    "# Convert the padded sequence to a NumPy array (if not already)\n",
    "rew_padded = np.array(rew_padded)\n",
    "prediction = best_model.predict(rew_padded.reshape(1, -1))\n",
    "sentiment = \"Positive\" if prediction > 0.5 else \"Negative\"\n",
    "print(f\"Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "57241236-fa2a-408a-97f9-2adc6afd065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "best_model.save('best_sentiment_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bdaddd22-f62b-49c8-bded-c4d60b1cb4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "952954db-b349-48d1-b0e5-1c1d65993b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d7aa7d-9937-4e54-871b-3fd94e0e5eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
